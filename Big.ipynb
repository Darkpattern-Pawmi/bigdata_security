{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqehTUitbxaV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "fwx_uUleUxBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzge5dM-U1DH",
        "outputId": "7cb6dd75-a9c9-43bd-82b0-b30381d8cfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uyrvxPhqu6mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aacc0be-9c23-4d81-d765-67fc6e705a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "# 파일을 바이너리 모드로 읽어서 인코딩 확인\n",
        "with open(\"/content/drive/MyDrive/bigdata/darkpattern_dataset_0601.csv\", 'rb') as file:\n",
        "    result = chardet.detect(file.read(10000))  # 처음 10000바이트만 읽어서 샘플링\n",
        "\n",
        "print(result['encoding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kAmSFuKolav",
        "outputId": "1162c638-a1d2-49d3-88b2-99ff51f3aff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utf-8\n"
          ]
        }
      ]
    },
    {
      "source": [
        "data = pd.read_csv(\"/content/dark_patterns_test.csv\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EE-9C4V10M3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xnu5764Yk1HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['word_count'] = data['text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# 한 단어만 존재하는 행 제거\n",
        "data = data[data['word_count'] > 1]"
      ],
      "metadata": {
        "id": "sThRy7rwbQ__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: dark_patterns_test_utf8.csv의 target열을 lable로 하고 y로감\n",
        "\n",
        "y = data[\"target\"]\n"
      ],
      "metadata": {
        "id": "y9h8SiTZmNPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['target'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o89DWCArpwxI",
        "outputId": "d12143df-eeda-45db-ae66-f1917158d8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "non-darkpattern    2171\n",
            "Scarcity            344\n",
            "Social Proof        312\n",
            "Urgency             196\n",
            "Misdirection        180\n",
            "Obstruction          27\n",
            "Sneaking             12\n",
            "Forced Action         4\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['text']\n",
        "dark_patterns = data['target']\n",
        "urls = data['url']"
      ],
      "metadata": {
        "id": "oWHAgXCtDXN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "texts = texts.replace(np.nan, '', regex=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_6UvkYpjLxf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#data['text'] = data['text'].astype(str)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2StNmUNFYwN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gYM1PC3ZTuC",
        "outputId": "59db2508-43fe-4fcb-f566-8bd1b4d663c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    I??�e read and accept the terms & conditions *...\n",
            "1    I accept the Terms & Conditions of the FREE Br...\n",
            "2    I would like to join Backstage Pass & agree to...\n",
            "3    I agree to receive marketing emails from Natur...\n",
            "4                        No thanks! I don't like deals\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    # 소문자 변환\n",
        "    text = text.lower()\n",
        "\n",
        "    # 특수 문자 제거\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
        "\n",
        "    # 토큰화\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 불용어 제거\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # 어간 추출 또는 표제어 추출\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # 공백 제거 및 다시 문장으로 결합\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "\n",
        "    return preprocessed_text\n"
      ],
      "metadata": {
        "id": "r7GTi8ZEU6FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "data.dtypes"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NFsp4F8YqkU",
        "outputId": "8ef0f2d7-5231-4c48-dd52-91d261655068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text           object\n",
              "target         object\n",
              "Unnamed: 2    float64\n",
              "url            object\n",
              "word_count      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "source": [
        "data['text'] = data['text'].astype(str)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9rLdL6oBXbdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['preprocessed_text'] = data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "7dZ-IbdpVMP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['preprocessed_text'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9N2xQ_LR-rS",
        "outputId": "c5298a7f-9db5-43cf-a7df-26882b1d1981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    i�e read accept term condition also authorize ...\n",
            "1    accept term condition free brother care progra...\n",
            "2    would like join backstage pas agree term condi...\n",
            "3    agree receive marketing email natural life agr...\n",
            "4                                thanks dont like deal\n",
            "Name: preprocessed_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def extract_text_features(preprocessed_text):\n",
        "    # 단어 빈도 피처 추출\n",
        "    count_vectorizer = CountVectorizer()\n",
        "    word_freq_features = count_vectorizer.fit_transform(preprocessed_text)\n",
        "\n",
        "    # TF-IDF 피처 추출\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_vectorizer.fit(preprocessed_text)\n",
        "    tfidf_features = tfidf_vectorizer.fit_transform(preprocessed_text)\n",
        "\n",
        "    # 감성 점수 계산\n",
        "    sentiment_scores = preprocessed_text.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "    # 단어 빈도 피처를 DataFrame으로 변환\n",
        "    features = pd.DataFrame(word_freq_features.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
        "\n",
        "    # tfidf_features를 DataFrame으로 추가\n",
        "    tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "    features = pd.concat([features, tfidf_df], axis=1)\n",
        "    features = pd.DataFrame(\n",
        "         data={\n",
        "             'sentiment': sentiment_scores,\n",
        "         }\n",
        "     )\n",
        "\n",
        "    return features\n",
        "\n",
        "# # 특성 추출을 위한 함수 정의\n",
        "# def extract_features(df):\n",
        "#     # N-gram 벡터화\n",
        "#     tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=2, max_df=0.95)\n",
        "#     tfidf_features = tfidf_vectorizer.fit_transform(df['text'])\n",
        "\n",
        "#     # 감성 점수 계산\n",
        "#     sentiment_scores = df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "#     # 텍스트 길이\n",
        "#     text_length = df['text'].apply(len)\n",
        "\n",
        "#     # DataFrame으로 특성 합치기\n",
        "#     features = pd.DataFrame(\n",
        "#         data={\n",
        "#             'sentiment': sentiment_scores,\n",
        "#             'text_length': text_length\n",
        "#         }\n",
        "#     )\n",
        "#     features = features.join(pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out()))\n",
        "\n",
        "#     return features"
      ],
      "metadata": {
        "id": "r8CzWflbFbbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSqDu4ywQOJc",
        "outputId": "47e17fcb-bc0b-44f9-feb1-778d6846e314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'target', 'Unnamed: 2', 'url', 'word_count',\n",
            "       'preprocessed_text'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = extract_text_features(data['preprocessed_text'])"
      ],
      "metadata": {
        "id": "QSr0DgBlKdwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ji7c3eJRnJEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "print(y_train.value_counts())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_XTEYN4nxx-",
        "outputId": "408f33fb-da5b-4d6c-90e1-0b68ffad9123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "non-darkpattern    1723\n",
            "Scarcity            277\n",
            "Social Proof        266\n",
            "Urgency             164\n",
            "Misdirection        134\n",
            "Obstruction          19\n",
            "Sneaking             10\n",
            "Forced Action         3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "dLHaAiB4tkQC",
        "outputId": "003ea773-ce77-4180-9123-ec8c90bb0713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "95KgpCI2tksN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuE2yeq9tlsE",
        "outputId": "4d5e8058-f350-4901-9c74-7a0700cd8304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6892307692307692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYoZGIVatvoL",
        "outputId": "e516f5b5-2aba-462c-fc27-afce86cc20d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  Forced Action       0.00      0.00      0.00         1\n",
            "   Misdirection       0.00      0.00      0.00        46\n",
            "    Obstruction       0.00      0.00      0.00         8\n",
            "       Scarcity       0.00      0.00      0.00        67\n",
            "       Sneaking       0.00      0.00      0.00         2\n",
            "   Social Proof       0.00      0.00      0.00        46\n",
            "        Urgency       0.00      0.00      0.00        32\n",
            "non-darkpattern       0.69      1.00      0.82       448\n",
            "\n",
            "       accuracy                           0.69       650\n",
            "      macro avg       0.09      0.12      0.10       650\n",
            "   weighted avg       0.48      0.69      0.56       650\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}